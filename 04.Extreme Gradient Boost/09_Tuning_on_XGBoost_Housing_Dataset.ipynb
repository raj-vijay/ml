{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "09. Tuning on XGBoost Housing Dataset.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMHMss1xfvjiX74dfhWMUoi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raj-vijay/ml/blob/master/04.Extreme%20Gradient%20Boost/09_Tuning_on_XGBoost_Housing_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jf94g7J4dzux"
      },
      "source": [
        "**Common tree tunable parameters**\n",
        "- learning rate: learning rate/eta\n",
        "- gamma: min loss reduction to create new tree split\n",
        "- lambda: L2 reg on leaf weights\n",
        "- alpha: L1 reg on leaf weights\n",
        "- max_depth: max depth per tree\n",
        "- subsample: % samples used per tree\n",
        "- colsample_bytree: % features used per tree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVMuy6tpd8U-"
      },
      "source": [
        "**Linear tunable parameters**\n",
        "- lambda: L2 reg on weights\n",
        "- alpha: L1 reg on weights\n",
        "- lambda_bias: L2 reg term on bias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxgNbNjdejM4"
      },
      "source": [
        "It's time to practice tuning other XGBoost hyperparameters in earnest and observing their effect on model performance! \n",
        "\n",
        "Now tune the \"eta\" / learning rate.\n",
        "\n",
        "The learning rate in XGBoost is a parameter that can range between 0 and 1, with higher values of \"eta\" penalizing feature weights more strongly, causing much stronger regularization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaSXqmUns3Wl"
      },
      "source": [
        "import xgboost as xgb\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXXPhQOev2Gf"
      },
      "source": [
        "from sklearn.datasets import load_boston\n",
        "X, y = load_boston(return_X_y=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0eWcgpox5Xj"
      },
      "source": [
        "# Create the training and test sets\n",
        "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.2, random_state=123)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1olOsswHcVNu"
      },
      "source": [
        "**Untuned Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcJlRfRs1fdG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "d9b665d2-bd8a-4519-a83f-3ec1f7f81f5f"
      },
      "source": [
        "# Create your housing DMatrix: housing_dmatrix\n",
        "housing_dmatrix = xgb.DMatrix(data=X, label=y)\n",
        "\n",
        "# Create the parameter dictionary for each tree (boosting round)\n",
        "params = {\"objective\":\"reg:squarederror\", \"max_depth\":3}\n",
        "\n",
        "# Create list of eta values and empty list to store final round rmse per xgboost model\n",
        "eta_vals = [0.001, 0.01, 0.1]\n",
        "best_rmse = []\n",
        "\n",
        "# Systematically vary the eta\n",
        "for curr_val in eta_vals:\n",
        "\n",
        "    params[\"eta\"] = curr_val\n",
        "    \n",
        "    # Perform cross-validation: cv_results\n",
        "    cv_results = xgb.cv(dtrain=housing_dmatrix, params=params, nfold=3,\n",
        "                        num_boost_round=10, early_stopping_rounds=5,\n",
        "                        metrics=\"rmse\", as_pandas=True, seed=123)\n",
        "    \n",
        "    # Append the final round rmse to best_rmse\n",
        "    best_rmse.append(cv_results[\"test-rmse-mean\"].tail().values[-1])\n",
        "\n",
        "# Print the resultant DataFrame\n",
        "print(pd.DataFrame(list(zip(eta_vals, best_rmse)), columns=[\"eta\",\"best_rmse\"]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     eta  best_rmse\n",
            "0  0.001  23.649514\n",
            "1  0.010  21.740976\n",
            "2  0.100   9.473431\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORbGjdKocIfA"
      },
      "source": [
        "**Tuned Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xlv8-tZ9e65e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "f21a90a7-e417-4a1d-b046-5fe19ab74784"
      },
      "source": [
        "# Create your housing DMatrix: housing_dmatrix\n",
        "housing_dmatrix = xgb.DMatrix(data=X,label=y)\n",
        "\n",
        "# Create the parameter dictionary\n",
        "params = {\"objective\":\"reg:squarederror\"}\n",
        "\n",
        "# Create list of max_depth values\n",
        "max_depths = [2, 5, 10, 20]\n",
        "best_rmse = []\n",
        "\n",
        "# Systematically vary the max_depth\n",
        "for curr_val in max_depths:\n",
        "\n",
        "    params[\"max_depth\"] = curr_val\n",
        "    \n",
        "    # Perform cross-validation\n",
        "    cv_results = xgb.cv(dtrain=housing_dmatrix, params=params, nfold=2,\n",
        "                 num_boost_round=10, early_stopping_rounds=5,\n",
        "                 metrics=\"rmse\", as_pandas=True, seed=123)\n",
        "    \n",
        "    # Append the final round rmse to best_rmse\n",
        "    best_rmse.append(cv_results[\"test-rmse-mean\"].tail().values[-1])\n",
        "\n",
        "# Print the resultant DataFrame\n",
        "print(pd.DataFrame(list(zip(max_depths, best_rmse)),columns=[\"max_depth\",\"best_rmse\"]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   max_depth  best_rmse\n",
            "0          2   4.097683\n",
            "1          5   3.867900\n",
            "2         10   3.840241\n",
            "3         20   3.806038\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKSgk1ncfSfm"
      },
      "source": [
        "**Tuning colsample_bytree**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6SUK-o9fS7O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "992d09e3-e074-47d0-fdb8-e0f3047309b5"
      },
      "source": [
        "# Create your housing DMatrix\n",
        "housing_dmatrix = xgb.DMatrix(data=X,label=y)\n",
        "\n",
        "# Create the parameter dictionary\n",
        "params={\"objective\":\"reg:squarederror\",\"max_depth\":3}\n",
        "\n",
        "# Create list of hyperparameter values\n",
        "colsample_bytree_vals = [0.1, 0.5, 0.8, 1]\n",
        "best_rmse = []\n",
        "\n",
        "# Systematically vary the hyperparameter value \n",
        "for curr_val in colsample_bytree_vals:\n",
        "\n",
        "    params[\"colsample_bytree\"] = curr_val\n",
        "    \n",
        "    # Perform cross-validation\n",
        "    cv_results = xgb.cv(dtrain=housing_dmatrix, params=params, nfold=2,\n",
        "                 num_boost_round=10, early_stopping_rounds=5,\n",
        "                 metrics=\"rmse\", as_pandas=True, seed=123)\n",
        "    \n",
        "    # Append the final round rmse to best_rmse\n",
        "    best_rmse.append(cv_results[\"test-rmse-mean\"].tail().values[-1])\n",
        "\n",
        "# Print the resultant DataFrame\n",
        "print(pd.DataFrame(list(zip(colsample_bytree_vals, best_rmse)), columns=[\"colsample_bytree\",\"best_rmse\"]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   colsample_bytree  best_rmse\n",
            "0               0.1   6.143021\n",
            "1               0.5   4.035454\n",
            "2               0.8   3.860411\n",
            "3               1.0   3.928074\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}