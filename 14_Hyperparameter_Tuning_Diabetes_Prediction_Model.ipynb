{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "14. Hyperparameter Tuning - Diabetes Prediction Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raj-vijay/ml/blob/master/14_Hyperparameter_Tuning_Diabetes_Prediction_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-uBah4Qn5t8",
        "colab_type": "text"
      },
      "source": [
        "**Hyperparameter tuning**\n",
        "\n",
        "Hyperparameter optimization or tuning is the problem of choosing a set of optimal hyperparameters for a machine learning algorithm. A hyperparameter is a parameter whose value is used to control the learning process. By contrast, the values of other parameters, viz. node weights, are learned.\n",
        "\n",
        "The same kind of machine learning model can require different constraints, weights or learning rates to generalize different data patterns. These measures are called hyperparameters, and have to be tuned so that the model can optimally solve the machine learning problem. \n",
        "\n",
        "Hyperparameter optimization finds a tuple of hyperparameters that yields an optimal model which minimizes a predefined loss function on given independent data. The objective function takes a tuple of hyperparameters and returns the associated loss. Cross-validation is often used to estimate this generalization performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WOjYU2Chw2a",
        "colab_type": "text"
      },
      "source": [
        "**Grid search**\n",
        "\n",
        "Grid search, or a parameter sweep, is a hyperparameter optimization technique that involves an exhaustive search through a manually specified subset of the hyperparameter space of a learning algorithm. \n",
        "\n",
        "A grid search algorithm is typically guided by a performance metric, measured by cross-validation on the training set or evaluation on a held-out validation set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdwrtRuxjLky",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://raw.githubusercontent.com/raj-vijay/ml/master/images/Grid_Search.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLMhUi4FDM5Q",
        "colab_type": "text"
      },
      "source": [
        "**Pima Indians Diabetes Database**\n",
        "\n",
        "Pima Indians Diabetes dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. \n",
        "\n",
        "The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. \n",
        "\n",
        "In particular, all patients here are females at least 21 years old of Pima Indian heritage.\n",
        "\n",
        "The dataset is imported from Kaggle.\n",
        "\n",
        "https://www.kaggle.com/uciml/pima-indians-diabetes-database"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPCdjYjZkJ3-",
        "colab_type": "text"
      },
      "source": [
        "Installing Kaggle Package to access the diabetes dataset from Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "My0q36n1jKX1",
        "colab_type": "code",
        "outputId": "a9db0328-9a69-4a24-8c37-e20505226599",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "!pip install kaggle"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.21.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.12.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.28.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2019.9.11)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.6.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EwkJ2BKkXO-",
        "colab_type": "text"
      },
      "source": [
        "Make .kaggle directory under root to import the Kaggle Authentication JSON."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWBE01UBjdk3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir ~/.kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p33pxUc9k6YF",
        "colab_type": "text"
      },
      "source": [
        "Change file path to root/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSxHC0E1jfTl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp /content/kaggle.json ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YC5_bG3Gkxfl",
        "colab_type": "text"
      },
      "source": [
        "Protect Kaggle JSON file for security reasons\n",
        "\n",
        "Chmod 600 (chmod a+rwx,u-x,g-rwx,o-rwx) sets permissions so that, (U)ser / owner can read, can write and can't execute. (G)roup can't read, can't write and can't execute. (O)thers can't read, can't write and can't execute."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqOCtvB3j4Iu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mkokc4SpmVLS",
        "colab_type": "text"
      },
      "source": [
        "Import the diabetes dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKg2TKatjx6W",
        "colab_type": "code",
        "outputId": "d2c03719-094f-4340-9cf5-4b5de47ddcae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!kaggle datasets download -d uciml/pima-indians-diabetes-database"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading pima-indians-diabetes-database.zip to /content\n",
            "\r  0% 0.00/8.91k [00:00<?, ?B/s]\n",
            "\r100% 8.91k/8.91k [00:00<00:00, 8.01MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmW3ARwmsEEi",
        "colab_type": "code",
        "outputId": "097d8d71-d9dc-4d74-9317-87f0a12eae6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "# Import numpy and pandas\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Read the diabetes dataset into a DataFrame: df\n",
        "df = pd.read_csv('pima-indians-diabetes-database.zip', compression='zip', header=0, sep=',', quotechar='\"')\n",
        "print(df)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     Pregnancies  Glucose  ...  Age  Outcome\n",
            "0              6      148  ...   50        1\n",
            "1              1       85  ...   31        0\n",
            "2              8      183  ...   32        1\n",
            "3              1       89  ...   21        0\n",
            "4              0      137  ...   33        1\n",
            "..           ...      ...  ...  ...      ...\n",
            "763           10      101  ...   63        0\n",
            "764            2      122  ...   27        0\n",
            "765            5      121  ...   30        0\n",
            "766            1      126  ...   47        1\n",
            "767            1       93  ...   23        0\n",
            "\n",
            "[768 rows x 9 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C35jiVBl_w9x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df.drop('Outcome', axis = 1)\n",
        "y = df['Outcome']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3BeF2cffsmU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import necessary modules\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dzlH3Fmfv4E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "7592fd34-d007-45c6-d883-362a994d7303"
      },
      "source": [
        "# Setup the hyperparameter grid\n",
        "c_space = np.logspace(-5, 8, 15)\n",
        "param_grid = {'C': c_space}\n",
        "print(c_space)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.00000000e-05 8.48342898e-05 7.19685673e-04 6.10540230e-03\n",
            " 5.17947468e-02 4.39397056e-01 3.72759372e+00 3.16227766e+01\n",
            " 2.68269580e+02 2.27584593e+03 1.93069773e+04 1.63789371e+05\n",
            " 1.38949549e+06 1.17876863e+07 1.00000000e+08]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqBBCh61fyT6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instantiate a logistic regression classifier: logreg\n",
        "logreg = LogisticRegression(solver = 'liblinear')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZS7Dy_lgaJc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instantiate the GridSearchCV object: logreg_cv\n",
        "logreg_cv = GridSearchCV(logreg, param_grid, cv=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gX-B0IjmgbQb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "4dec3612-e6c5-4002-db34-6a68bb46e816"
      },
      "source": [
        "# Fit it to the data\n",
        "logreg_cv.fit(X,y)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
              "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                          fit_intercept=True,\n",
              "                                          intercept_scaling=1, l1_ratio=None,\n",
              "                                          max_iter=100, multi_class='warn',\n",
              "                                          n_jobs=None, penalty='l2',\n",
              "                                          random_state=None, solver='liblinear',\n",
              "                                          tol=0.0001, verbose=0,\n",
              "                                          warm_start=False),\n",
              "             iid='warn', n_jobs=None,\n",
              "             param_grid={'C': array([1.00000000e-05, 8.48342898e-05, 7.19685673e-04, 6.10540230e-03,\n",
              "       5.17947468e-02, 4.39397056e-01, 3.72759372e+00, 3.16227766e+01,\n",
              "       2.68269580e+02, 2.27584593e+03, 1.93069773e+04, 1.63789371e+05,\n",
              "       1.38949549e+06, 1.17876863e+07, 1.00000000e+08])},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2BnjeLnglk8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "21b3404b-031c-4e1b-87f1-9557129a5f6f"
      },
      "source": [
        "# Print the tuned parameters and score\n",
        "print(\"Tuned Logistic Regression Parameters: {}\".format(logreg_cv.best_params_)) \n",
        "print(\"Best score is {}\".format(logreg_cv.best_score_))\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tuned Logistic Regression Parameters: {'C': 2275.845926074791}\n",
            "Best score is 0.7708333333333334\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}